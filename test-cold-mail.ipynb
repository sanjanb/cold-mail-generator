{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13786840,"sourceType":"datasetVersion","datasetId":8776636}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:10:13.290607Z","iopub.execute_input":"2025-11-19T05:10:13.290935Z","iopub.status.idle":"2025-11-19T05:10:13.651743Z","shell.execute_reply.started":"2025-11-19T05:10:13.290910Z","shell.execute_reply":"2025-11-19T05:10:13.650723Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/portfolio/my_portfolio.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install langchain_groq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:10:13.653389Z","iopub.execute_input":"2025-11-19T05:10:13.653785Z","iopub.status.idle":"2025-11-19T05:10:21.177787Z","shell.execute_reply.started":"2025-11-19T05:10:13.653761Z","shell.execute_reply":"2025-11-19T05:10:21.176496Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain_groq\n  Downloading langchain_groq-1.0.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting groq<1.0.0,>=0.30.0 (from langchain_groq)\n  Downloading groq-0.35.0-py3-none-any.whl.metadata (16 kB)\nCollecting langchain-core<2.0.0,>=1.0.2 (from langchain_groq)\n  Downloading langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.11.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (0.28.1)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (2.12.4)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.15.0)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (1.33)\nRequirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (0.4.8)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (25.0)\nRequirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (6.0.3)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (9.1.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain_groq) (3.11)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain_groq) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (3.11.0)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (2.32.5)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (2.5.0)\nDownloading langchain_groq-1.0.1-py3-none-any.whl (17 kB)\nDownloading groq-0.35.0-py3-none-any.whl (137 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-1.0.5-py3-none-any.whl (471 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: groq, langchain-core, langchain_groq\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.72\n    Uninstalling langchain-core-0.3.72:\n      Successfully uninstalled langchain-core-0.3.72\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.5 which is incompatible.\nlangchain-text-splitters 0.3.9 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed groq-0.35.0 langchain-core-1.0.5 langchain_groq-1.0.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Using groqclouds api to fetch the information we want through a llm model in the cloud","metadata":{}},{"cell_type":"code","source":"from langchain_groq import ChatGroq\nfrom IPython.display import Markdown, display\n\nllm = ChatGroq(\n    model_name=\"llama-3.3-70b-versatile\",\n    groq_api_key=\"YOUR-GROQ-API-KEY\",\n    temperature=0,\n    max_tokens=None,\n    timeout=None,\n    max_retries=2\n)\n\nresponse = llm.invoke(\"who is the inventor of deep learning ?\")\n# print(response.content)\nMarkdown(response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:10:21.178966Z","iopub.execute_input":"2025-11-19T05:10:21.179276Z","iopub.status.idle":"2025-11-19T05:10:33.370225Z","shell.execute_reply.started":"2025-11-19T05:10:21.179243Z","shell.execute_reply":"2025-11-19T05:10:33.368937Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The invention of deep learning is a bit complex, as it is a subfield of machine learning that has evolved over time through the contributions of many researchers. While it is difficult to attribute the invention of deep learning to a single person, some key figures have played a significant role in its development.\n\nSome notable researchers who have made significant contributions to the development of deep learning include:\n\n1. **David Rumelhart**, **Geoffrey Hinton**, and **Yann LeCun**: They are often referred to as the \"Godfathers of Deep Learning.\" In the 1980s and 1990s, they worked on the development of backpropagation, a key algorithm used in training deep neural networks.\n2. **Yann LeCun**: LeCun is often credited with developing the first deep learning algorithm, called LeNet-1, in the 1990s. He also developed the LeNet-5 algorithm, which is still used today.\n3. **Geoffrey Hinton**: Hinton is a prominent researcher in the field of deep learning. He has made significant contributions to the development of deep neural networks, including the introduction of the concept of \"deep learning\" in the 2000s.\n4. **Andrew Ng** and **Fei-Fei Li**: They have also made significant contributions to the development of deep learning, particularly in the area of computer vision.\n\nHowever, if I had to choose one person who is often referred to as the \"inventor\" of deep learning, it would be **Geoffrey Hinton**. Hinton's work on deep neural networks, particularly his 2006 paper \"A Fast Learning Algorithm for Deep Belief Nets,\" is often cited as a key milestone in the development of deep learning.\n\nKeep in mind that the development of deep learning is a continuous process, and many researchers have contributed to its evolution over the years."},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"!pip install chromadb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:10:33.371314Z","iopub.execute_input":"2025-11-19T05:10:33.371666Z","iopub.status.idle":"2025-11-19T05:10:56.225724Z","shell.execute_reply.started":"2025-11-19T05:10:33.371629Z","shell.execute_reply":"2025-11-19T05:10:56.224398Z"}},"outputs":[{"name":"stdout","text":"Collecting chromadb\n  Downloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.12.4)\nCollecting pybase64>=1.4.1 (from chromadb)\n  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\nRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\nCollecting posthog<6.0.0,>=2.4.0 (from chromadb)\n  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.15.0)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.37.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.37.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.3)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.2.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\nRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (25.0)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nCollecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (6.33.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.7.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.22.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.5->chromadb) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\nDownloading httptools-0.7.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (456 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.6/456.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.22.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.1/456.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=8fb6bfbf19daf0ec53c48a7a6d8b0fe857e341922be98948857e7733536f6f47\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, durationpy, uvloop, urllib3, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, cachetools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-semantic-conventions, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, onnxruntime, chromadb\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.5.0\n    Uninstalling urllib3-2.5.0:\n      Successfully uninstalled urllib3-2.5.0\n  Attempting uninstall: opentelemetry-proto\n    Found existing installation: opentelemetry-proto 1.37.0\n    Uninstalling opentelemetry-proto-1.37.0:\n      Successfully uninstalled opentelemetry-proto-1.37.0\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 6.2.1\n    Uninstalling cachetools-6.2.1:\n      Successfully uninstalled cachetools-6.2.1\n  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.37.0\n    Uninstalling opentelemetry-api-1.37.0:\n      Successfully uninstalled opentelemetry-api-1.37.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.37.0\n    Uninstalling opentelemetry-sdk-1.37.0:\n      Successfully uninstalled opentelemetry-sdk-1.37.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-adk 1.18.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\ngoogle-adk 1.18.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\nlangchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.5 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 cachetools-5.5.2 chromadb-1.3.5 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":" ### Using chroma vector db to store the documents, that will be used in the project later","metadata":{}},{"cell_type":"markdown","source":"## Example 1","metadata":{}},{"cell_type":"code","source":"import chromadb\n\nclient = chromadb.Client()\ncollection = client.create_collection(name='my_colection')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:10:56.228546Z","iopub.execute_input":"2025-11-19T05:10:56.228889Z","iopub.status.idle":"2025-11-19T05:11:02.196547Z","shell.execute_reply.started":"2025-11-19T05:10:56.228858Z","shell.execute_reply":"2025-11-19T05:11:02.195510Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"collection.add(\n    documents=[\n        'This doc is about reccurent nn',\n        'This doc is about convolutional nn',\n        'This doc is about artificial nn'\n    ],\n    ids = ['id1','id2','id3']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:11:02.197497Z","iopub.execute_input":"2025-11-19T05:11:02.197978Z","iopub.status.idle":"2025-11-19T05:11:06.963984Z","shell.execute_reply.started":"2025-11-19T05:11:02.197953Z","shell.execute_reply":"2025-11-19T05:11:06.963067Z"}},"outputs":[{"name":"stderr","text":"/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:02<00:00, 31.6MiB/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"all_doc = collection.get()\nall_doc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:11:06.964899Z","iopub.execute_input":"2025-11-19T05:11:06.965201Z","iopub.status.idle":"2025-11-19T05:11:06.977388Z","shell.execute_reply.started":"2025-11-19T05:11:06.965170Z","shell.execute_reply":"2025-11-19T05:11:06.975799Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'ids': ['id1', 'id2', 'id3'],\n 'embeddings': None,\n 'documents': ['This doc is about reccurent nn',\n  'This doc is about convolutional nn',\n  'This doc is about artificial nn'],\n 'uris': None,\n 'included': ['metadatas', 'documents'],\n 'data': None,\n 'metadatas': [None, None, None]}"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"We don't use traditional database because, you can query the db using normal english and get the semantic and contextual answers","metadata":{}},{"cell_type":"code","source":"results = collection.query(\n    query_texts = ['Query is about filters to extract the image features'],\n    n_results = 2\n)\n\nresults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:11:06.978617Z","iopub.execute_input":"2025-11-19T05:11:06.978897Z","iopub.status.idle":"2025-11-19T05:11:07.337177Z","shell.execute_reply.started":"2025-11-19T05:11:06.978875Z","shell.execute_reply":"2025-11-19T05:11:07.336184Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'ids': [['id2', 'id1']],\n 'embeddings': None,\n 'documents': [['This doc is about convolutional nn',\n   'This doc is about reccurent nn']],\n 'uris': None,\n 'included': ['metadatas', 'documents', 'distances'],\n 'data': None,\n 'metadatas': [[None, None]],\n 'distances': [[1.4924646615982056, 1.7825058698654175]]}"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"- As you can see the first doc I got is CNN, because the query was about filters to extracts the features in the image, which is called convolutional layers\n- At the bottom, they have given us the distance which is the distance between the contextual and meaning of the words in the document and the query\n- the minimum distance is the nearest query search\n","metadata":{}},{"cell_type":"markdown","source":"### Example 2","metadata":{}},{"cell_type":"code","source":"collection.add(\n    documents=[\n        \"This document is about New York\",\n        \"This document is about Delhi\"\n    ],\n    ids=[\"id3\", \"id4\"],\n    metadatas=[\n        {\"url\": \"https://en.wikipedia.org/wiki/New_York_City\"},\n        {\"url\": \"https://en.wikipedia.org/wiki/New_Delhi\"}\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:11:07.338343Z","iopub.execute_input":"2025-11-19T05:11:07.338588Z","iopub.status.idle":"2025-11-19T05:11:07.743661Z","shell.execute_reply.started":"2025-11-19T05:11:07.338560Z","shell.execute_reply":"2025-11-19T05:11:07.742448Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"results = collection.query(\n    query_texts=[\"Query is about Chhole Bhature\"],\n    n_results=2\n)\nresults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:11:07.744672Z","iopub.execute_input":"2025-11-19T05:11:07.745002Z","iopub.status.idle":"2025-11-19T05:11:08.083731Z","shell.execute_reply.started":"2025-11-19T05:11:07.744973Z","shell.execute_reply":"2025-11-19T05:11:08.082718Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'ids': [['id1', 'id4']],\n 'embeddings': None,\n 'documents': [['This doc is about reccurent nn',\n   'This document is about Delhi']],\n 'uris': None,\n 'included': ['metadatas', 'documents', 'distances'],\n 'data': None,\n 'metadatas': [[None, {'url': 'https://en.wikipedia.org/wiki/New_Delhi'}]],\n 'distances': [[1.4777404069900513, 1.5588479042053223]]}"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## Lets know more about langchain's web based loder","metadata":{}},{"cell_type":"code","source":"!pip install langchain_community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:11:08.084785Z","iopub.execute_input":"2025-11-19T05:11:08.085311Z","iopub.status.idle":"2025-11-19T05:11:16.723933Z","shell.execute_reply.started":"2025-11-19T05:11:08.085278Z","shell.execute_reply":"2025-11-19T05:11:16.722937Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting langchain_community\n  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.0.5)\nCollecting langchain-classic<2.0.0,>=1.0.0 (from langchain_community)\n  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\nRequirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.5)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.13.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.11.0)\nRequirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.8)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.3)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\nCollecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain_community)\n  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.4)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (25.0)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.5)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain_community) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain_community) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain_community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\nDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\nInstalling collected packages: langchain-text-splitters, langchain-classic, langchain_community\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.9\n    Uninstalling langchain-text-splitters-0.3.9:\n      Successfully uninstalled langchain-text-splitters-0.3.9\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.5 which is incompatible.\nlangchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-classic-1.0.0 langchain-text-splitters-1.0.0 langchain_community-0.4.1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from langchain_community.document_loaders import WebBaseLoader\n\nloader = WebBaseLoader(\"https://www.wearedevelopers.com/en/companies/3853/picnic-technologies/47673/machine-learning-engineer\")\npage_data = loader.load().pop().page_content\nprint(page_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:15:07.377825Z","iopub.execute_input":"2025-11-19T05:15:07.378271Z","iopub.status.idle":"2025-11-19T05:15:08.795671Z","shell.execute_reply.started":"2025-11-19T05:15:07.378233Z","shell.execute_reply":"2025-11-19T05:15:08.794682Z"}},"outputs":[{"name":"stdout","text":"\n\n\nMachine Learning Engineer at Picnic Technologies B.V. in Amsterdam\n\n\nWAD Home Page   \n              Discover\n             \n              LIVE\n             \n              Podcast\n             \n              Magazine\n             \n              Tech Jobs\n             \n              Companies\n             \n              Events\n             \n              For Business\n                    \n        Skip to main content\n        Solutions \n                        Employer Branding\n                       \n                        Tech Recruiting\n                       \n                        Product Marketing\n                       \n                        Event Partnerships\n                       2026\n                        Post a job\n                       Products \n                        Talent Marketing Membership\n                       \n                        Product Marketing Membership\n                       \n                        WeAreDevelopers World Congress\n                       \n                        Job Platform\n                       Insights \n                        Resources\n                       \n                        Developer survey\n                       \n                        Salary calculator\n                       \n                        Newsletter\n                       \n                        Blog\n                        For Developers \n                        World Congress 2026\n                       Europe \n                    Berlin, Germany, 8-10th July 2026\n                  \n                        World Congress 2026\n                       North America \n                    San Jos√©, CA, 23-25th September 2026\n                  \n                        Conference 2026\n                       India \n                    Bengaluru, India, Spring 2026\n                  For Tech Leaders \n                        Tech Leaders Summit 2026\n                       Europe \n                    Berlin, Germany, 8-10th July 2026\n                  For Leaders in HR/TA/Recruiting \n                        HR Leaders Summit 2026\n                       Europe \n                    Berlin, Germany, 8-10th July 2026\n                               \n          Machine Learning Engineer\n         supervisor_account\n        Picnic Technologies B.V.\n         room\n        Amsterdam, Netherlands\n        stars\n        Intermediate\n      stars\n        Senior\n        translate\n        English\n       \n        Python\n      \n        Structured Query Language (SQL)\n      \n        Machine Learning\n           \n            APPLY NOW\n           Login to apply or Signup for free.\n            Machine Learning Engineer at Picnic Technologies B.V. Requirements Master‚Äôs degree or higher in AI, Computer Science, Mathematics, or a related fieldAt least 2 years of experience in data science or applied machine learningExcellent communication skills, you can clearly explain complex ideas in non-technical terms and enjoy working closely with business stakeholders to solve problems togetherSome experience with maintaining production-level ML solutions and eager to learn about solid software engineering principles and ML principlesStrong Python and SQL skillsExperience with Docker, Kubernetes, and CI is a plus Scope of Work You will definitely:Identify and execute improvement possibilities together with other ML Engineers and (product) analysts Collaborate on your project from inception to production, to continuous improvementDevelop tools and enhancements for our cloud-based Machine Learning platformYou could work on various projects and fields, such as: Demand forecasting: delivery, article, trip volumes, used Picnic-wideFraud detection: helping us keep troublemakers out of our storeRecommendation systems: generating useful in-app grocery suggestions Search and ranking: helping our customers find exactly what they needPredicting delivery drop-off times: making sure we‚Äôre on-time at every customer‚Äôs doorVision: ensuring quality control and smooth operations within our warehouses Check out some of our previous machine learning projects here:  https://blog.picnic.nl/tagged/machine-learning Benefits ‚úçüèº Every expert was once a beginner! You‚Äôll get plenty of opportunities to challenge yourself and grow, including the Picnic Tech Academy, Lunch & Learn sessions, and tailored soft skills training. We also offer free professional weekly language courses. ü´±üèº‚Äçü´≤üèæ Teamwork makes the dream workWith more than 80 nationalities across 3 countries, you‚Äôll be part of a diverse company with plenty of cool stuff to get involved with, from board game evenings to after-work drinks to our company ski trip and more! ü•ó Fresh Lunch, coffee, and snacks Our offices are equipped with fully-fledged coffee bars and a kitchen and chefs. They prepare delicious fresh and warm lunches every day so you can keep your energy up. üö≤ Health insurance discount & bike planWe have a partnership with CZ (a health insurance provider). Picnic employees get a discount on CZ insurance packages between 5% and 15%. Furthermore, through our partnership with Lease a Bike, you can rent-to-own a new (e)bike at a discounted rate üåé RelocationIf you‚Äôre moving from another country to join Picnic we make it as smooth as possible for you. We‚Äôll cover your flight costs for you and your partner and kids, your first month's rent and moving costs (up to ‚Ç¨2000), and help you with the 30% tax ruling setup and application.  üìÜ All the rest At Picnic you get 25 holidays, we cover your travel expenses and offer a pension plan. And your phone and laptop are on us, as well.    Applicant Location Requirements roomON SITE\n         in¬†\n          Amsterdam (Netherlands).   About Picnic Technologies B.V. From using deep learning models to forecast future orders to a fully automated warehouse: Picnic‚Äôs tech team is at the core of it all. You‚Äôll join a truly unique and groundbreaking operation since we‚Äôre the only supermarket in the world that‚Äôs built everything from the ground up. Up for the challenge?    \n        Events\n       LiveWorld CongressCODE100\n        Developers\n       JobsCompaniesMagazineTech TalksCommunityNewsletter\n        Social\n       FacebookInstagramXYouTubeLinkedIn\n        WeAreDevelopers\n       AboutTeamCareerContactPressLegalCookiesImprint \n    ¬© 2025 WeAreDevelopers\n   \n\n\n\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"To get the exact information what we want, we can use a specifica prompt to get the exact information we want from the website","metadata":{}},{"cell_type":"code","source":"from langchain_core.prompts import PromptTemplate\n\nprompt_extract = PromptTemplate.from_template(\n        \"\"\"\n        ### SCRAPED TEXT FROM WEBSITE:\n        {page_data}\n        ### INSTRUCTION:\n        The scraped text is from the career's page of a website.\n        Your job is to extract the job postings and return them in JSON format containing the \n        following keys: `role`, `experience`, `skills` and `description`.\n        Only return the valid JSON.\n        ### VALID JSON (NO PREAMBLE):    \n        \"\"\"\n)\n\nchain_extract = prompt_extract | llm \nres = chain_extract.invoke(input={'page_data':page_data})\n# type(res.content)\nprint(res.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:15:57.747516Z","iopub.execute_input":"2025-11-19T05:15:57.747854Z","iopub.status.idle":"2025-11-19T05:15:58.307402Z","shell.execute_reply.started":"2025-11-19T05:15:57.747829Z","shell.execute_reply":"2025-11-19T05:15:58.306424Z"}},"outputs":[{"name":"stdout","text":"```json\n{\n  \"role\": \"Machine Learning Engineer\",\n  \"experience\": \"Intermediate, Senior\",\n  \"skills\": [\n    \"Python\",\n    \"Structured Query Language (SQL)\",\n    \"Machine Learning\",\n    \"Docker\",\n    \"Kubernetes\",\n    \"CI\"\n  ],\n  \"description\": \"We are looking for a Machine Learning Engineer to join our team. The ideal candidate will have a Master's degree or higher in AI, Computer Science, Mathematics, or a related field, and at least 2 years of experience in data science or applied machine learning. The candidate should have excellent communication skills, be able to clearly explain complex ideas in non-technical terms, and enjoy working closely with business stakeholders to solve problems together. The candidate will identify and execute improvement possibilities, collaborate on projects from inception to production, and develop tools and enhancements for our cloud-based Machine Learning platform.\"\n}\n```\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from langchain_core.output_parsers import JsonOutputParser\n\njson_parser = JsonOutputParser()\njson_res = json_parser.parse(res.content)\njson_res","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:16:02.562993Z","iopub.execute_input":"2025-11-19T05:16:02.564195Z","iopub.status.idle":"2025-11-19T05:16:02.582597Z","shell.execute_reply.started":"2025-11-19T05:16:02.564150Z","shell.execute_reply":"2025-11-19T05:16:02.581694Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'role': 'Machine Learning Engineer',\n 'experience': 'Intermediate, Senior',\n 'skills': ['Python',\n  'Structured Query Language (SQL)',\n  'Machine Learning',\n  'Docker',\n  'Kubernetes',\n  'CI'],\n 'description': \"We are looking for a Machine Learning Engineer to join our team. The ideal candidate will have a Master's degree or higher in AI, Computer Science, Mathematics, or a related field, and at least 2 years of experience in data science or applied machine learning. The candidate should have excellent communication skills, be able to clearly explain complex ideas in non-technical terms, and enjoy working closely with business stakeholders to solve problems together. The candidate will identify and execute improvement possibilities, collaborate on projects from inception to production, and develop tools and enhancements for our cloud-based Machine Learning platform.\"}"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"type(json_res)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:16:05.702969Z","iopub.execute_input":"2025-11-19T05:16:05.704014Z","iopub.status.idle":"2025-11-19T05:16:05.710725Z","shell.execute_reply.started":"2025-11-19T05:16:05.703983Z","shell.execute_reply":"2025-11-19T05:16:05.709258Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"dict"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/portfolio/my_portfolio.csv\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:16:05.864066Z","iopub.execute_input":"2025-11-19T05:16:05.864984Z","iopub.status.idle":"2025-11-19T05:16:05.884462Z","shell.execute_reply.started":"2025-11-19T05:16:05.864948Z","shell.execute_reply":"2025-11-19T05:16:05.883099Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                               Techstack  \\\n0                React, Node.js, MongoDB   \n1               Angular,.NET, SQL Server   \n2      Vue.js, Ruby on Rails, PostgreSQL   \n3                  Python, Django, MySQL   \n4              Java, Spring Boot, Oracle   \n5             Flutter, Firebase, GraphQL   \n6                  WordPress, PHP, MySQL   \n7                    Magento, PHP, MySQL   \n8         React Native, Node.js, MongoDB   \n9                  iOS, Swift, Core Data   \n10       Android, Java, Room Persistence   \n11             Kotlin, Android, Firebase   \n12       Android TV, Kotlin, Android NDK   \n13                     iOS, Swift, ARKit   \n14        Cross-platform, Xamarin, Azure   \n15          Backend, Kotlin, Spring Boot   \n16         Frontend, TypeScript, Angular   \n17    Full-stack, JavaScript, Express.js   \n18  Machine Learning, Python, TensorFlow   \n19               DevOps, Jenkins, Docker   \n\n                                                Links  \n0                 https://example.com/react-portfolio  \n1               https://example.com/angular-portfolio  \n2                   https://example.com/vue-portfolio  \n3                https://example.com/python-portfolio  \n4                  https://example.com/java-portfolio  \n5               https://example.com/flutter-portfolio  \n6             https://example.com/wordpress-portfolio  \n7               https://example.com/magento-portfolio  \n8          https://example.com/react-native-portfolio  \n9                   https://example.com/ios-portfolio  \n10              https://example.com/android-portfolio  \n11       https://example.com/kotlin-android-portfolio  \n12           https://example.com/android-tv-portfolio  \n13               https://example.com/ios-ar-portfolio  \n14              https://example.com/xamarin-portfolio  \n15       https://example.com/kotlin-backend-portfolio  \n16  https://example.com/typescript-frontend-portfolio  \n17        https://example.com/full-stack-js-portfolio  \n18            https://example.com/ml-python-portfolio  \n19               https://example.com/devops-portfolio  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Techstack</th>\n      <th>Links</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>React, Node.js, MongoDB</td>\n      <td>https://example.com/react-portfolio</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Angular,.NET, SQL Server</td>\n      <td>https://example.com/angular-portfolio</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Vue.js, Ruby on Rails, PostgreSQL</td>\n      <td>https://example.com/vue-portfolio</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Python, Django, MySQL</td>\n      <td>https://example.com/python-portfolio</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Java, Spring Boot, Oracle</td>\n      <td>https://example.com/java-portfolio</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Flutter, Firebase, GraphQL</td>\n      <td>https://example.com/flutter-portfolio</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>WordPress, PHP, MySQL</td>\n      <td>https://example.com/wordpress-portfolio</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Magento, PHP, MySQL</td>\n      <td>https://example.com/magento-portfolio</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>React Native, Node.js, MongoDB</td>\n      <td>https://example.com/react-native-portfolio</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>iOS, Swift, Core Data</td>\n      <td>https://example.com/ios-portfolio</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Android, Java, Room Persistence</td>\n      <td>https://example.com/android-portfolio</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Kotlin, Android, Firebase</td>\n      <td>https://example.com/kotlin-android-portfolio</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Android TV, Kotlin, Android NDK</td>\n      <td>https://example.com/android-tv-portfolio</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>iOS, Swift, ARKit</td>\n      <td>https://example.com/ios-ar-portfolio</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Cross-platform, Xamarin, Azure</td>\n      <td>https://example.com/xamarin-portfolio</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Backend, Kotlin, Spring Boot</td>\n      <td>https://example.com/kotlin-backend-portfolio</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Frontend, TypeScript, Angular</td>\n      <td>https://example.com/typescript-frontend-portfolio</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Full-stack, JavaScript, Express.js</td>\n      <td>https://example.com/full-stack-js-portfolio</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Machine Learning, Python, TensorFlow</td>\n      <td>https://example.com/ml-python-portfolio</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DevOps, Jenkins, Docker</td>\n      <td>https://example.com/devops-portfolio</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import uuid\nimport chromadb\n\nclient = chromadb.PersistentClient('vectorstore')\ncollection = client.get_or_create_collection(name=\"portfolio\")\n\nif not collection.count():\n    for _, row in df.iterrows():\n        collection.add(documents=row[\"Techstack\"],\n                       metadatas={\"links\": row[\"Links\"]},\n                       ids=[str(uuid.uuid4())])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:16:09.613958Z","iopub.execute_input":"2025-11-19T05:16:09.614315Z","iopub.status.idle":"2025-11-19T05:16:09.626641Z","shell.execute_reply.started":"2025-11-19T05:16:09.614290Z","shell.execute_reply":"2025-11-19T05:16:09.625420Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"job = json_res\njob['skills']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:16:29.785246Z","iopub.execute_input":"2025-11-19T05:16:29.785597Z","iopub.status.idle":"2025-11-19T05:16:29.793020Z","shell.execute_reply.started":"2025-11-19T05:16:29.785571Z","shell.execute_reply":"2025-11-19T05:16:29.791689Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"['Python',\n 'Structured Query Language (SQL)',\n 'Machine Learning',\n 'Docker',\n 'Kubernetes',\n 'CI']"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"job","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:16:34.328666Z","iopub.execute_input":"2025-11-19T05:16:34.329020Z","iopub.status.idle":"2025-11-19T05:16:34.336039Z","shell.execute_reply.started":"2025-11-19T05:16:34.328994Z","shell.execute_reply":"2025-11-19T05:16:34.334906Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'role': 'Machine Learning Engineer',\n 'experience': 'Intermediate, Senior',\n 'skills': ['Python',\n  'Structured Query Language (SQL)',\n  'Machine Learning',\n  'Docker',\n  'Kubernetes',\n  'CI'],\n 'description': \"We are looking for a Machine Learning Engineer to join our team. The ideal candidate will have a Master's degree or higher in AI, Computer Science, Mathematics, or a related field, and at least 2 years of experience in data science or applied machine learning. The candidate should have excellent communication skills, be able to clearly explain complex ideas in non-technical terms, and enjoy working closely with business stakeholders to solve problems together. The candidate will identify and execute improvement possibilities, collaborate on projects from inception to production, and develop tools and enhancements for our cloud-based Machine Learning platform.\"}"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"links = collection.query(query_texts=job['skills'], n_results=2).get('metadatas', [])\nlinks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:17:24.562382Z","iopub.execute_input":"2025-11-19T05:17:24.562717Z","iopub.status.idle":"2025-11-19T05:17:25.269406Z","shell.execute_reply.started":"2025-11-19T05:17:24.562690Z","shell.execute_reply":"2025-11-19T05:17:25.268467Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[[{'links': 'https://example.com/ml-python-portfolio'},\n  {'links': 'https://example.com/python-portfolio'}],\n [{'links': 'https://example.com/magento-portfolio'},\n  {'links': 'https://example.com/python-portfolio'}],\n [{'links': 'https://example.com/ml-python-portfolio'},\n  {'links': 'https://example.com/wordpress-portfolio'}],\n [{'links': 'https://example.com/devops-portfolio'},\n  {'links': 'https://example.com/ios-ar-portfolio'}],\n [{'links': 'https://example.com/devops-portfolio'},\n  {'links': 'https://example.com/kotlin-backend-portfolio'}],\n [{'links': 'https://example.com/magento-portfolio'},\n  {'links': 'https://example.com/ios-ar-portfolio'}]]"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"prompt_email = PromptTemplate.from_template(\n        \"\"\"\n        ### JOB DESCRIPTION:\n        {job_description}\n        \n        ### INSTRUCTION:\n        You are Mohan, a business development executive at AtliQ. AtliQ is an AI & Software Consulting company dedicated to facilitating\n        the seamless integration of business processes through automated tools. \n        Over our experience, we have empowered numerous enterprises with tailored solutions, fostering scalability, \n        process optimization, cost reduction, and heightened overall efficiency. \n        Your job is to write a cold email to the client regarding the job mentioned above describing the capability of AtliQ \n        in fulfilling their needs.\n        Also add the most relevant ones from the following links to showcase Atliq's portfolio: {link_list}\n        Remember you are Mohan, BDE at AtliQ. \n        Do not provide a preamble.\n        ### EMAIL (NO PREAMBLE):\n        \n        \"\"\"\n        )\n\nchain_email = prompt_email | llm\nres = chain_email.invoke({\"job_description\": str(job), \"link_list\": links})\nprint(res.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:17:26.250865Z","iopub.execute_input":"2025-11-19T05:17:26.251232Z","iopub.status.idle":"2025-11-19T05:17:27.148685Z","shell.execute_reply.started":"2025-11-19T05:17:26.251205Z","shell.execute_reply":"2025-11-19T05:17:27.147720Z"}},"outputs":[{"name":"stdout","text":"Subject: Expert Machine Learning Solutions for Your Business\n\nDear Hiring Manager,\n\nI came across your job posting for a Machine Learning Engineer and was impressed by the role's requirements. As a Business Development Executive at AtliQ, an AI & Software Consulting company, I believe our team can help you find the perfect candidate or even provide a tailored solution to fulfill your machine learning needs.\n\nAt AtliQ, we have a proven track record of empowering enterprises with scalable, optimized, and efficient solutions. Our expertise in machine learning, Python, and cloud-based platforms can help you identify and execute improvement possibilities, collaborate on projects from inception to production, and develop tools and enhancements for your cloud-based Machine Learning platform.\n\nOur portfolio showcases our capabilities in machine learning and Python, with notable projects including:\n- https://example.com/ml-python-portfolio\n- https://example.com/python-portfolio\n- https://example.com/devops-portfolio\n\nThese examples demonstrate our ability to develop and implement machine learning models, work with Python, and leverage DevOps practices to ensure seamless integration and deployment. Our team is well-versed in Docker, Kubernetes, and CI, ensuring that our solutions are scalable, efficient, and reliable.\n\nI'd love to discuss how AtliQ can help you achieve your machine learning goals. Please let me know if you're interested in scheduling a call to explore further.\n\nBest regards,\nMohan\nBusiness Development Executive\nAtliQ\n","output_type":"stream"}],"execution_count":34}]}